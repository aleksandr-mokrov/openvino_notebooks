{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Image generation with Segmind Stable Diffusion 1B (SSD-1B) model and OpenVINO\n",
    "\n",
    "The [Segmind Stable Diffusion Model (SSD-1B)](https://github.com/segmind/SSD-1B?ref=blog.segmind.com) is a distilled 50% smaller version of the Stable Diffusion XL (SDXL), offering a 60% speedup while maintaining high-quality text-to-image generation capabilities. It has been trained on diverse datasets, including Grit and Midjourney scrape data, to enhance its ability to create a wide range of visual content based on textual prompts.\n",
    "This model employs a knowledge distillation strategy, where it leverages the teachings of several expert models in succession, including SDXL, ZavyChromaXL, and JuggernautXL, to combine their strengths and produce impressive visual outputs.\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/82945616/277419571-a5583e8a-6a05-4680-a540-f80502feed0b.png)\n",
    "\n",
    "\n",
    "In this tutorial, we consider how to run the SSD-1B model using OpenVINO.\n",
    "\n",
    "We will use a pre-trained model from the [Hugging Face Diffusers](https://huggingface.co/docs/diffusers/index) library. To simplify the user experience, the [Hugging Face Optimum Intel](https://huggingface.co/docs/optimum/intel/index) library is used to convert the models to OpenVINO™ IR format.\n",
    "\n",
    "#### Table of content:\n",
    "- [Install Prerequisites](#Install-prerequisites-Uparrow)\n",
    "- [SSD-1B Base model](#SSD-1B-Base-model-Uparrow)\n",
    "- [Select inference device SSD-1B Base model](#Select-inference-device-SSD-1B-Base-model-Uparrow)\n",
    "- [Text2image Generation Interactive Demo](#Text2image-Generation-Interactive-Demo-Uparrow)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73eedd1846fbbc76"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Install prerequisites [$\\Uparrow$](#Table-of-content:)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5e736551f15ee21"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%pip install -q \"git+https://github.com/huggingface/optimum-intel.git\"\n",
    "%pip install -q \"openvino>=2023.1.0\"\n",
    "%pip install -q --upgrade-strategy eager \"invisible-watermark>=0.2.0\" \"transformers>=4.30.2\" \"accelerate\" \"onnx\" \"onnxruntime\" safetensors\n",
    "%pip install -q git+https://github.com/huggingface/diffusers\n",
    "%pip install -q gradio"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T13:35:19.220747700Z",
     "start_time": "2023-10-31T13:35:19.220747700Z"
    }
   },
   "id": "d9d7b5772c33bc6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SSD-1B Base model [$\\Uparrow$](#Table-of-content:)\n",
    "\n",
    "We will start with the base model part, which is responsible for the generation of images of the desired output size. \n",
    "[SSD-1B](https://huggingface.co/segmind/SSD-1B) is available for downloading via the [HuggingFace hub](https://huggingface.co/models). It already provides a ready-to-use model in OpenVINO format compatible with [Optimum Intel](https://huggingface.co/docs/optimum/intel/index).\n",
    "\n",
    "To load an OpenVINO model and run an inference with OpenVINO Runtime, you need to replace diffusers `StableDiffusionXLPipeline` with Optimum `OVStableDiffusionXLPipeline`. In case you want to load a PyTorch model and convert it to the OpenVINO format on the fly, you can set `export=True`.  \n",
    "\n",
    "You can save the model on disk using the `save_pretrained` method."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf52326c380ca9fc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from optimum.intel.openvino import OVStableDiffusionXLPipeline\n",
    "\n",
    "\n",
    "model_id = \"segmind/SSD-1B\"\n",
    "model_dir = Path(\"openvino-ssd-1b\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d28ca20bc63cc9b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Select inference device SSD-1B Base model [$\\Uparrow$](#Table-of-content:)\n",
    "\n",
    "select device from dropdown list for running inference using OpenVINO"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c1b73f7f7b2ec5d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import openvino as ov\n",
    "\n",
    "\n",
    "core = ov.Core()\n",
    "\n",
    "device = widgets.Dropdown(\n",
    "    options=core.available_devices + [\"AUTO\"],\n",
    "    value='AUTO',\n",
    "    description='Device:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "device"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8bc866dd4513a227"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "\n",
    "if not model_dir.exists():\n",
    "    text2image_pipe = OVStableDiffusionXLPipeline.from_pretrained(model_id, compile=False, device=device.value, export=True)\n",
    "    text2image_pipe.half()\n",
    "    text2image_pipe.save_pretrained(model_dir)\n",
    "    text2image_pipe.compile()\n",
    "    gc.collect()\n",
    "else:\n",
    "    text2image_pipe = OVStableDiffusionXLPipeline.from_pretrained(model_dir, device=device.value)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e170d7fb8271f0b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Run Text2Image generation pipeline [$\\Uparrow$](#Table-of-content:)\n",
    "\n",
    "Now, we can run the model for the generation of images using text prompts. To speed up evaluation and reduce the required memory we decrease `num_inference_steps` and image size (using `height` and `width`).  You can modify them to suit your needs and depend on the target hardware. We also specified a `generator` parameter based on a numpy random state with a specific seed for results reproducibility.\n",
    ">**Note**: Generating a default size 1024x1024 image requires about 53GB for the SSD-1B model in case if the converted model is loaded from disk and up to 64GB RAM for the SDXL model after exporting."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9fce7a3b2f805652"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prompt = \"An astronaut riding a green horse\"  # Your prompt here\n",
    "neg_prompt = \"ugly, blurry, poor quality\"  # Negative prompt here\n",
    "image = text2image_pipe(prompt=prompt, num_inference_steps=15, negative_prompt=neg_prompt).images[0]\n",
    "image"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed145470184014ff"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generating a 512x512 image requires about 27GB for the SSD-1B model and about 42GB RAM for the SDXL model in case if the converted model is loaded from disk."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d814c52f181d2be6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "prompt = \"cute cat 4k, high-res, masterpiece, best quality, soft lighting, dynamic angle\"\n",
    "image = text2image_pipe(prompt, num_inference_steps=15, height=512, width=512, generator=np.random.RandomState(314)).images[0]\n",
    "image"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be7b2783f2102b1a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Image2Image Generation Interactive Demo [$\\Uparrow$](#Table-of-content:)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32dff8c3c4923c4f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "if text2image_pipe is None:\n",
    "    text2image_pipe = OVStableDiffusionXLPipeline.from_pretrained(model_dir, device=device.value)\n",
    "\n",
    "prompt = \"An astronaut riding a green horse\"\n",
    "neg_prompt = \"ugly, blurry, poor quality\"\n",
    "\n",
    "def generate_from_text(text, seed, num_steps):\n",
    "    result = text2image_pipe(text, num_inference_steps=num_steps, generator=np.random.RandomState(seed), height=512, width=512).images[0]\n",
    "    return result\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Column():\n",
    "        positive_input = gr.Textbox(label=\"Text prompt\")\n",
    "        neg_input = gr.Textbox(label=\"Text prompt\")\n",
    "        with gr.Row():\n",
    "            seed_input = gr.Number(precision=0, label=\"Seed\", value=42, minimum=0)\n",
    "            steps_input = gr.Slider(label=\"Steps\", value=10)\n",
    "            btn = gr.Button()\n",
    "        out = gr.Image(label=\"Result\", type=\"pil\", width=512)\n",
    "        btn.click(generate_from_text, [positive_input, seed_input, steps_input], out)\n",
    "        gr.Examples([\n",
    "            [prompt, neg_prompt, 999, 20], \n",
    "            [\"underwater world coral reef, colorful jellyfish, 35mm, cinematic lighting, shallow depth of field,  ultra quality, masterpiece, realistic\", neg_prompt, 89, 20],\n",
    "            [\"a photo realistic happy white poodle dog ​​playing in the grass, extremely detailed, high res, 8k, masterpiece, dynamic angle\", neg_prompt, 1569, 15],\n",
    "            [\"Astronaut on Mars watching sunset, best quality, cinematic effects,\", neg_prompt, 65245, 12],\n",
    "            [\"Black and white street photography of a rainy night in New York, reflections on wet pavement\", neg_prompt, 48199, 10]\n",
    "        ], [positive_input, neg_input, seed_input, steps_input])\n",
    "\n",
    "# if you are launching remotely, specify server_name and server_port\n",
    "# demo.launch(server_name='your server name', server_port='server port in int')\n",
    "# Read more in the docs: https://gradio.app/docs/\n",
    "# if you want to create public link for sharing demo, please add share=True\n",
    "demo.launch()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18a2de015398e5bb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
