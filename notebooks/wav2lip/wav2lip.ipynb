{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36104004-1d8e-4890-ab87-990ade94dcc5",
   "metadata": {},
   "source": [
    "# Wav2Lip: Accurately Lip-syncing Videos and OpenVINO\n",
    "\n",
    "Lip sync technologies are widely used for digital human use cases, which enhance the user experience in dialog scenarios.\n",
    "\n",
    "[Wav2Lip](https://github.com/Rudrabha/Wav2Lip) is a novel approach to generate accurate 2D lip-synced videos in the wild with only one video and an audio clip. Wav2Lip leverages an accurate lip-sync “expert\" model and consecutive face frames for accurate, natural lip motion generation.\n",
    "\n",
    "In this notebook, we introduce how to enable and optimize Wav2Lippipeline with OpenVINO. This is adaptation of the blog article [Enable 2D Lip Sync Wav2Lip Pipeline with OpenVINO Runtime](https://blog.openvino.ai/blog-posts/enable-2d-lip-sync-wav2lip-pipeline-with-openvino-runtime).\n",
    "\n",
    "Here is Wav2Lip pipeline overview:\n",
    "\n",
    "![wav2lip_pipeline](https://cdn.prod.website-files.com/62c72c77b482b372ac273024/669487bc70c2767fbb9b6c8e_wav2lip_pipeline.png)\n",
    "\n",
    "\n",
    "#### Table of contents:\n",
    "\n",
    "- [Prerequisites](#Prerequisites)\n",
    "- [Convert the model to OpenVINO IR](#Convert-the-model-to-OpenVINO-IR)\n",
    "- [Compiling models and prepare pipeline](#Compiling-models-and-prepare-pipeline)\n",
    "- [Interactive inference](#Interactive-inference)\n",
    "\n",
    "### Installation Instructions\n",
    "\n",
    "This is a self-contained example that relies solely on its own code.\n",
    "\n",
    "We recommend  running the notebook in a virtual environment. You only need a Jupyter server to start.\n",
    "For details, please refer to [Installation Guide](https://github.com/openvinotoolkit/openvino_notebooks/blob/latest/README.md#-installation-guide).\n",
    "\n",
    "<img referrerpolicy=\"no-referrer-when-downgrade\" src=\"https://static.scarf.sh/a.png?x-pxid=5b5a4db0-7875-4bfb-bdbd-01698b5b1a77&file=notebooks/wav2lip/wav2lip.ipynb\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62451f48-e48c-4d1a-b41d-d112b703939f",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "[back to top ⬆️](#Table-of-contents:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aaf7ac-b7b1-4d69-a27a-8fa1757cf330",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install  -q \"openvino>=2024.3.0\"\n",
    "%pip install -q huggingface_hub \"torch>=2.1\" --extra-index-url https://download.pytorch.org/whl/cpu\n",
    "%pip install -q \"librosa==0.9.2\" opencv-contrib-python opencv-python tqdm numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aba4ed8-d668-4295-a1f3-d42a82cdbf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get(\n",
    "    url=\"https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/utils/notebook_utils.py\",\n",
    ")\n",
    "\n",
    "open(\"notebook_utils.py\", \"w\").write(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc14eca8-15c7-4e61-9e26-9d1172562239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "wav2lip_path = Path(\"Wav2Lip\")\n",
    "\n",
    "if not wav2lip_path.exists():\n",
    "    wav2lip_path.mkdir(parents=True, exist_ok=True)\n",
    "    !git clone https://github.com/Rudrabha/Wav2Lip\n",
    "\n",
    "sys.path.append(str(wav2lip_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aedd043-5078-4685-a199-6c5d523122b3",
   "metadata": {},
   "source": [
    "Download example files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06198a5a-6646-4bcc-abb3-8ed3e98be33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils import download_file\n",
    "\n",
    "\n",
    "download_file(\"https://github.com/sammysun0711/openvino_aigc_samples/blob/main/Wav2Lip/data_audio_sun_5s.wav?raw=true\")\n",
    "download_file(\"https://github.com/sammysun0711/openvino_aigc_samples/blob/main/Wav2Lip/data_video_sun_5s.mp4?raw=true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cfa3ef-ce99-455c-ae23-d3092c2b4905",
   "metadata": {},
   "source": [
    "### Convert the model to OpenVINO IR\n",
    "[back to top ⬆️](#Table-of-contents:)\n",
    "\n",
    "You don't need to download checkpoints and load models, just call the helper function `download_and_convert_models`. It takes care about it and will convert both model in OpenVINO format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73728210-64dd-4791-b2db-59098a23ab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ov_wav2lip_helper import download_and_convert_models\n",
    "\n",
    "\n",
    "OV_FACE_DETECTION_MODEL_PATH = Path(\"models/face_detection.xml\")\n",
    "OV_WAV2LIP_MODEL_PATH = Path(\"models/wav2lip.xml\")\n",
    "\n",
    "download_and_convert_models(OV_FACE_DETECTION_MODEL_PATH, OV_WAV2LIP_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e645fe5-c1c5-4db3-8973-3d65864e00af",
   "metadata": {},
   "source": [
    "## Compiling models and prepare pipeline\n",
    "[back to top ⬆️](#Table-of-contents:)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6ad00a-d3c9-4de4-8d74-be98a193c1da",
   "metadata": {},
   "source": [
    "Select device from dropdown list for running inference using OpenVINO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4257000c-83da-4ab2-81ef-0931992207b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils import device_widget\n",
    "\n",
    "device = device_widget()\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f544dd-bdd0-42d7-81a0-4c38467e7531",
   "metadata": {},
   "source": [
    "`ov_inference.py` is an adaptation of original pipeline that has only cli-interface. `ov_inference` allows running the inference using python API and converted OpenVINO models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6032dd4f-8d80-4a63-aa01-466fb96c1e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ov_inference import ov_inference\n",
    "\n",
    "\n",
    "ov_inference(\n",
    "    \"data_video_sun_5s.mp4\",\n",
    "    \"data_audio_sun_5s.wav\",\n",
    "    face_detection_path=OV_FACE_DETECTION_MODEL_PATH,\n",
    "    wav2lip_path=OV_WAV2LIP_MODEL_PATH,\n",
    "    inference_device=device.value,\n",
    "    outfile=\"results/result_voice.mp4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0933d0af-4934-4348-8f33-a989e7f2ae74",
   "metadata": {},
   "source": [
    "Here is an example to compare original video and generated video after the Wav2Lip pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceedf90-f4b5-4d6d-a7da-2a1487387c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(\"data_video_sun_5s.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfa7d0a-5525-4a60-aea2-01808d30f767",
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(\"results/result_voice.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "openvino_notebooks": {
   "imageUrl": "https://huggingface.co/numz/wav2lip_studio/resolve/main/demo/demo.gif",
   "tags": {
    "categories": [
     "Model Demos",
     "AI Trends"
    ],
    "libraries": [],
    "other": [],
    "tasks": [
     "Audio-to-Video",
     "Lip-Sync"
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
