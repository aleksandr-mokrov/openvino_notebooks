{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# High-Quality Text-Free One-Shot Voice Conversion with FeeVC and OpenVINOâ„¢"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-requisites\n",
    "1. Clone this repo: git clone https://github.com/OlaWod/FreeVC.git\n",
    "2. Download [WavLM-Large](https://github.com/microsoft/unilm/tree/master/wavlm) and put it under directory 'FreeVC/wavlm/'\n",
    "3. Download the [VCTK](https://datashare.ed.ac.uk/handle/10283/3443) dataset (will be replaced by our examples). You can use any of them, but for this example you should use `vctk-16k/p225/p225_001.wav` and `vctk-16k/p226/p226_002.wav`. Put them under directory 'dataset'. To use other examples, you should change `convert.txt`.\n",
    "4. Download [pretrained models](https://1drv.ms/u/s!AnvukVnlQ3ZTx1rjrOZ2abCwuBAh?e=UlhRR5) and put it under directory 'checkpoints' (for current example only `freevc.pth` are required)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Install extra requirements"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "!pip install -q \"librosa>=0.8.1\"\n",
    "!pip install webrtcvad==2.0.10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check if FreeVC is installed and its path to sys.path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "\n",
    "free_vc_repo = 'FreeVC'\n",
    "if not Path(free_vc_repo).exists():\n",
    "    !git clone https://github.com/OlaWod/FreeVC.git\n",
    "\n",
    "sys.path.append(free_vc_repo)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T00:27:26.828826Z",
     "end_time": "2023-05-02T00:27:28.801560Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports and settings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import librosa\n",
    "import torch\n",
    "from scipy.io.wavfile import write\n",
    "from tqdm import tqdm\n",
    "\n",
    "import utils\n",
    "from models import SynthesizerTrn\n",
    "from speaker_encoder.voice_encoder import SpeakerEncoder\n",
    "from wavlm import WavLM, WavLMConfig"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T00:28:10.780215Z",
     "end_time": "2023-05-02T00:28:12.782590Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Redefine function `get_model`form `utils` to exclude cuda"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_cmodel():\n",
    "    checkpoint = torch.load('wavlm/WavLM-Large.pt')\n",
    "    cfg = WavLMConfig(checkpoint['cfg'])\n",
    "    cmodel = WavLM(cfg)\n",
    "    cmodel.load_state_dict(checkpoint['model'])\n",
    "    cmodel.eval()\n",
    "\n",
    "    return cmodel"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T00:28:16.524338Z",
     "end_time": "2023-05-02T00:28:18.501408Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Models initialization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded checkpoint 'checkpoints/freevc.pth' (iteration 1372)\n",
      "INFO:wavlm.WavLM:WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}\n",
      "Loaded the voice encoder model on cpu in 0.09 seconds.\n"
     ]
    }
   ],
   "source": [
    "hps = utils.get_hparams_from_file('configs/freevc.json')\n",
    "os.makedirs('outputs/freevc', exist_ok=True)\n",
    "\n",
    "net_g = SynthesizerTrn(\n",
    "    hps.data.filter_length // 2 + 1,\n",
    "    hps.train.segment_size // hps.data.hop_length,\n",
    "    **hps.model\n",
    ")\n",
    "\n",
    "utils.load_checkpoint('checkpoints/freevc.pth', net_g, optimizer=None, strict=True)\n",
    "cmodel = get_cmodel()\n",
    "smodel = SpeakerEncoder('FreeVC/speaker_encoder/ckpt/pretrained_bak_5805000.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-28T16:58:52.768410Z",
     "end_time": "2023-04-28T16:59:03.795031Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reading dataset settings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "titles, srcs, tgts = [], [], []\n",
    "\n",
    "with open('convert.txt', \"r\") as f:\n",
    "    for rawline in f.readlines():\n",
    "        title, src, tgt = rawline.strip().split(\"|\")\n",
    "        titles.append(title)\n",
    "        srcs.append(src)\n",
    "        tgts.append(tgt)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Inference"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:03,  1.99s/it]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for line in tqdm(zip(titles, srcs, tgts)):\n",
    "        title, src, tgt = line\n",
    "        # tgt\n",
    "        wav_tgt, _ = librosa.load(tgt, sr=hps.data.sampling_rate)\n",
    "        wav_tgt, _ = librosa.effects.trim(wav_tgt, top_db=20)\n",
    "\n",
    "        g_tgt = smodel.embed_utterance(wav_tgt)\n",
    "        g_tgt = torch.from_numpy(g_tgt).unsqueeze(0)\n",
    "\n",
    "        # src\n",
    "        wav_src, _ = librosa.load(src, sr=hps.data.sampling_rate)\n",
    "        wav_src = torch.from_numpy(wav_src).unsqueeze(0)\n",
    "        c = utils.get_content(cmodel, wav_src)\n",
    "\n",
    "        audio = net_g.infer(c, g=g_tgt)\n",
    "        audio = audio[0][0].data.cpu().float().numpy()\n",
    "\n",
    "        timestamp = time.strftime(\"%m-%d_%H-%M\", time.localtime())\n",
    "        write(os.path.join('outputs/freevc', \"{}.wav\".format(timestamp + \"_\" + title)), hps.data.sampling_rate,\n",
    "              audio)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T13:52:32.402545Z",
     "end_time": "2023-04-26T13:52:50.046902Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Results audio files should be available in 'outputs/freevc'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "# Use Model Optimizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T00:38:38.439058Z",
     "end_time": "2023-05-02T00:38:40.167704Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# define forward as extract_features for compatibility\n",
    "cmodel.forward = cmodel.extract_features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T00:49:16.943230Z",
     "end_time": "2023-05-02T00:49:16.975658Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (1). Kernel size: (10). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/openvino/frontend/pytorch/decoder.py:148\u001B[0m, in \u001B[0;36mTorchScriptPythonDecoder._get_scripted_model\u001B[0;34m(self, pt_module, example_inputs, freeze)\u001B[0m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 148\u001B[0m     scripted \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrace\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpt_module\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/torch/jit/_trace.py:759\u001B[0m, in \u001B[0;36mtrace\u001B[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001B[0m\n\u001B[1;32m    758\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func, torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mModule):\n\u001B[0;32m--> 759\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrace_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    760\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    761\u001B[0m \u001B[43m        \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mforward\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mexample_inputs\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    762\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    763\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_trace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    764\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwrap_check_inputs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcheck_inputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    765\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_tolerance\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    766\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstrict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    767\u001B[0m \u001B[43m        \u001B[49m\u001B[43m_force_outplace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    768\u001B[0m \u001B[43m        \u001B[49m\u001B[43m_module_class\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    769\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    771\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    772\u001B[0m     \u001B[38;5;28mhasattr\u001B[39m(func, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__self__\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    773\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__self__\u001B[39m, torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mModule)\n\u001B[1;32m    774\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m func\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mforward\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    775\u001B[0m ):\n",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/torch/jit/_trace.py:976\u001B[0m, in \u001B[0;36mtrace_module\u001B[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001B[0m\n\u001B[1;32m    974\u001B[0m example_inputs \u001B[38;5;241m=\u001B[39m make_tuple(example_inputs)\n\u001B[0;32m--> 976\u001B[0m \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_c\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_method_from_trace\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    977\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    978\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    979\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexample_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    980\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvar_lookup_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    981\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstrict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    982\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_force_outplace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    983\u001B[0m \u001B[43m    \u001B[49m\u001B[43margument_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    984\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    985\u001B[0m check_trace_method \u001B[38;5;241m=\u001B[39m module\u001B[38;5;241m.\u001B[39m_c\u001B[38;5;241m.\u001B[39m_get_method(method_name)\n",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/torch/nn/modules/module.py:1182\u001B[0m, in \u001B[0;36mModule._slow_forward\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1181\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1182\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1183\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "File \u001B[0;32m/mnt/c/Users/amokrov/PycharmProjects/default/my_openvino_notebooks/notebooks/freevc/wavlm/WavLM.py:334\u001B[0m, in \u001B[0;36mWavLM.extract_features\u001B[0;34m(self, source, padding_mask, mask, ret_conv, output_layer, ret_layer_results)\u001B[0m\n\u001B[1;32m    333\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_grad_mult \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 334\u001B[0m     features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeature_extractor\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    335\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_grad_mult \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m1.0\u001B[39m:\n",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/torch/nn/modules/module.py:1182\u001B[0m, in \u001B[0;36mModule._slow_forward\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1181\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1182\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1183\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "File \u001B[0;32m/mnt/c/Users/amokrov/PycharmProjects/default/my_openvino_notebooks/notebooks/freevc/wavlm/WavLM.py:500\u001B[0m, in \u001B[0;36mConvFeatureExtractionModel.forward\u001B[0;34m(self, x, mask)\u001B[0m\n\u001B[1;32m    499\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m conv \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv_layers:\n\u001B[0;32m--> 500\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mconv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    501\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconv2d\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/torch/nn/modules/module.py:1182\u001B[0m, in \u001B[0;36mModule._slow_forward\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1181\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1182\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1183\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/torch/nn/modules/container.py:204\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    203\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 204\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    205\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/torch/nn/modules/module.py:1182\u001B[0m, in \u001B[0;36mModule._slow_forward\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1181\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1182\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1183\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/torch/nn/modules/conv.py:313\u001B[0m, in \u001B[0;36mConv1d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    312\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 313\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/torch/nn/modules/conv.py:309\u001B[0m, in \u001B[0;36mConv1d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    306\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv1d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[1;32m    307\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    308\u001B[0m                     _single(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[0;32m--> 309\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv1d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    310\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Calculated padded input size per channel: (1). Kernel size: (10). Kernel size can't be greater than actual input size",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/openvino/frontend/pytorch/decoder.py:151\u001B[0m, in \u001B[0;36mTorchScriptPythonDecoder._get_scripted_model\u001B[0;34m(self, pt_module, example_inputs, freeze)\u001B[0m\n\u001B[1;32m    150\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 151\u001B[0m     scripted \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscript\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpt_module\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    152\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/torch/jit/_script.py:1286\u001B[0m, in \u001B[0;36mscript\u001B[0;34m(obj, optimize, _frames_up, _rcb, example_inputs)\u001B[0m\n\u001B[1;32m   1285\u001B[0m     obj \u001B[38;5;241m=\u001B[39m call_prepare_scriptable_func(obj)\n\u001B[0;32m-> 1286\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_recursive\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_script_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1287\u001B[0m \u001B[43m        \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_recursive\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minfer_methods_to_compile\u001B[49m\n\u001B[1;32m   1288\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1290\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj, \u001B[38;5;28mdict\u001B[39m):\n",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/torch/jit/_recursive.py:476\u001B[0m, in \u001B[0;36mcreate_script_module\u001B[0;34m(nn_module, stubs_fn, share_types, is_tracing)\u001B[0m\n\u001B[1;32m    475\u001B[0m     AttributeTypeIsSupportedChecker()\u001B[38;5;241m.\u001B[39mcheck(nn_module)\n\u001B[0;32m--> 476\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcreate_script_module_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnn_module\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconcrete_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstubs_fn\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/torch/jit/_recursive.py:538\u001B[0m, in \u001B[0;36mcreate_script_module_impl\u001B[0;34m(nn_module, concrete_type, stubs_fn)\u001B[0m\n\u001B[1;32m    537\u001B[0m \u001B[38;5;66;03m# Actually create the ScriptModule, initializing it with the function we just defined\u001B[39;00m\n\u001B[0;32m--> 538\u001B[0m script_module \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mRecursiveScriptModule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_construct\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcpp_module\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minit_fn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    540\u001B[0m \u001B[38;5;66;03m# Compile methods if necessary\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/torch/jit/_script.py:615\u001B[0m, in \u001B[0;36mRecursiveScriptModule._construct\u001B[0;34m(cpp_module, init_fn)\u001B[0m\n\u001B[1;32m    614\u001B[0m script_module \u001B[38;5;241m=\u001B[39m RecursiveScriptModule(cpp_module)\n\u001B[0;32m--> 615\u001B[0m \u001B[43minit_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mscript_module\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    617\u001B[0m \u001B[38;5;66;03m# Finalize the ScriptModule: replace the nn.Module state with our\u001B[39;00m\n\u001B[1;32m    618\u001B[0m \u001B[38;5;66;03m# custom implementations and flip the _initializing bit.\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/torch/jit/_recursive.py:516\u001B[0m, in \u001B[0;36mcreate_script_module_impl.<locals>.init_fn\u001B[0;34m(script_module)\u001B[0m\n\u001B[1;32m    514\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    515\u001B[0m     \u001B[38;5;66;03m# always reuse the provided stubs_fn to infer the methods to compile\u001B[39;00m\n\u001B[0;32m--> 516\u001B[0m     scripted \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_script_module_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43morig_value\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msub_concrete_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstubs_fn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    518\u001B[0m cpp_module\u001B[38;5;241m.\u001B[39msetattr(name, scripted)\n",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/torch/jit/_recursive.py:538\u001B[0m, in \u001B[0;36mcreate_script_module_impl\u001B[0;34m(nn_module, concrete_type, stubs_fn)\u001B[0m\n\u001B[1;32m    537\u001B[0m \u001B[38;5;66;03m# Actually create the ScriptModule, initializing it with the function we just defined\u001B[39;00m\n\u001B[0;32m--> 538\u001B[0m script_module \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mRecursiveScriptModule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_construct\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcpp_module\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minit_fn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    540\u001B[0m \u001B[38;5;66;03m# Compile methods if necessary\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/torch/jit/_script.py:615\u001B[0m, in \u001B[0;36mRecursiveScriptModule._construct\u001B[0;34m(cpp_module, init_fn)\u001B[0m\n\u001B[1;32m    614\u001B[0m script_module \u001B[38;5;241m=\u001B[39m RecursiveScriptModule(cpp_module)\n\u001B[0;32m--> 615\u001B[0m \u001B[43minit_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mscript_module\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    617\u001B[0m \u001B[38;5;66;03m# Finalize the ScriptModule: replace the nn.Module state with our\u001B[39;00m\n\u001B[1;32m    618\u001B[0m \u001B[38;5;66;03m# custom implementations and flip the _initializing bit.\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/torch/jit/_recursive.py:516\u001B[0m, in \u001B[0;36mcreate_script_module_impl.<locals>.init_fn\u001B[0;34m(script_module)\u001B[0m\n\u001B[1;32m    514\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    515\u001B[0m     \u001B[38;5;66;03m# always reuse the provided stubs_fn to infer the methods to compile\u001B[39;00m\n\u001B[0;32m--> 516\u001B[0m     scripted \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_script_module_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43morig_value\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msub_concrete_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstubs_fn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    518\u001B[0m cpp_module\u001B[38;5;241m.\u001B[39msetattr(name, scripted)\n",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/torch/jit/_recursive.py:538\u001B[0m, in \u001B[0;36mcreate_script_module_impl\u001B[0;34m(nn_module, concrete_type, stubs_fn)\u001B[0m\n\u001B[1;32m    537\u001B[0m \u001B[38;5;66;03m# Actually create the ScriptModule, initializing it with the function we just defined\u001B[39;00m\n\u001B[0;32m--> 538\u001B[0m script_module \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mRecursiveScriptModule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_construct\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcpp_module\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minit_fn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    540\u001B[0m \u001B[38;5;66;03m# Compile methods if necessary\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/torch/jit/_script.py:615\u001B[0m, in \u001B[0;36mRecursiveScriptModule._construct\u001B[0;34m(cpp_module, init_fn)\u001B[0m\n\u001B[1;32m    614\u001B[0m script_module \u001B[38;5;241m=\u001B[39m RecursiveScriptModule(cpp_module)\n\u001B[0;32m--> 615\u001B[0m \u001B[43minit_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mscript_module\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    617\u001B[0m \u001B[38;5;66;03m# Finalize the ScriptModule: replace the nn.Module state with our\u001B[39;00m\n\u001B[1;32m    618\u001B[0m \u001B[38;5;66;03m# custom implementations and flip the _initializing bit.\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/torch/jit/_recursive.py:516\u001B[0m, in \u001B[0;36mcreate_script_module_impl.<locals>.init_fn\u001B[0;34m(script_module)\u001B[0m\n\u001B[1;32m    514\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    515\u001B[0m     \u001B[38;5;66;03m# always reuse the provided stubs_fn to infer the methods to compile\u001B[39;00m\n\u001B[0;32m--> 516\u001B[0m     scripted \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_script_module_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43morig_value\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msub_concrete_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstubs_fn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    518\u001B[0m cpp_module\u001B[38;5;241m.\u001B[39msetattr(name, scripted)\n",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/torch/jit/_recursive.py:490\u001B[0m, in \u001B[0;36mcreate_script_module_impl\u001B[0;34m(nn_module, concrete_type, stubs_fn)\u001B[0m\n\u001B[1;32m    489\u001B[0m property_stubs \u001B[38;5;241m=\u001B[39m get_property_stubs(nn_module)\n\u001B[0;32m--> 490\u001B[0m hook_stubs, pre_hook_stubs \u001B[38;5;241m=\u001B[39m \u001B[43mget_hook_stubs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnn_module\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    492\u001B[0m user_annotated_ignored_attributes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(nn_module, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__jit_ignored_attributes__\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mlist\u001B[39m())\n",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/torch/jit/_recursive.py:783\u001B[0m, in \u001B[0;36mget_hook_stubs\u001B[0;34m(nn_module)\u001B[0m\n\u001B[1;32m    782\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m pre_hook \u001B[38;5;129;01min\u001B[39;00m nn_module\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\u001B[38;5;241m.\u001B[39mvalues():\n\u001B[0;32m--> 783\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mpre_hook\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__name__\u001B[39;49m \u001B[38;5;129;01min\u001B[39;00m hook_map:\n\u001B[1;32m    784\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mid\u001B[39m(pre_hook) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mid\u001B[39m(hook_map[pre_hook\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m]):\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'WeightNorm' object has no attribute '__name__'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mopenvino\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtools\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m mo\n\u001B[0;32m----> 4\u001B[0m ir_model \u001B[38;5;241m=\u001B[39m \u001B[43mmo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_shape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcompress_to_fp16\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/openvino/tools/mo/convert.py:351\u001B[0m, in \u001B[0;36mconvert_model\u001B[0;34m(input_model, help, framework, input, output, input_shape, batch, mean_values, scale_values, scale, reverse_input_channels, source_layout, target_layout, layout, compress_to_fp16, extensions, transform, transformations_config, silent, log_level, version, progress, stream_output, example_input, onnx_opset_version, input_model_is_text, input_checkpoint, input_meta_graph, saved_model_dir, saved_model_tags, tensorflow_custom_operations_config_update, tensorflow_object_detection_api_pipeline_config, tensorboard_logdir, tensorflow_custom_layer_libraries, input_symbol, nd_prefix_name, pretrained_model_name, save_params_from_nd, legacy_mxnet_model, enable_ssd_gluoncv, input_proto, caffe_parser_path, k, disable_omitting_optional, enable_flattening_nested_params, counts, remove_output_softmax, remove_memory, **args)\u001B[0m\n\u001B[1;32m    349\u001B[0m params\u001B[38;5;241m.\u001B[39mupdate(args)\n\u001B[1;32m    350\u001B[0m cli_parser \u001B[38;5;241m=\u001B[39m get_all_cli_parser()\n\u001B[0;32m--> 351\u001B[0m ov_model, _ \u001B[38;5;241m=\u001B[39m \u001B[43m_convert\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcli_parser\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframework\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    352\u001B[0m restore_logger_state(logger_state)\n\u001B[1;32m    353\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ov_model\n",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/openvino/tools/mo/convert_impl.py:984\u001B[0m, in \u001B[0;36m_convert\u001B[0;34m(cli_parser, framework, args, python_api_used)\u001B[0m\n\u001B[1;32m    982\u001B[0m send_conversion_result(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfail\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    983\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m python_api_used:\n\u001B[0;32m--> 984\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    985\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    986\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, argv\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Calculated padded input size per channel: (1). Kernel size: (10). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "from openvino.tools import mo\n",
    "\n",
    "\n",
    "ir_model = mo.convert_model(cmodel, input_shape=[1, -1], compress_to_fp16=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert cmodel to ONNX"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/amokrov/PycharmProjects/default/my_openvino_notebooks/notebooks/freevc/wavlm/WavLM.py:352: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if mask:\n",
      "/mnt/c/Users/amokrov/PycharmProjects/default/my_openvino_notebooks/notebooks/freevc/wavlm/modules.py:495: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert embed_dim == self.embed_dim\n",
      "/mnt/c/Users/amokrov/PycharmProjects/default/my_openvino_notebooks/notebooks/freevc/wavlm/modules.py:496: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert list(query.size()) == [tgt_len, bsz, embed_dim]\n",
      "/mnt/c/Users/amokrov/PycharmProjects/default/my_openvino_notebooks/notebooks/freevc/wavlm/modules.py:500: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert key_bsz == bsz\n",
      "/mnt/c/Users/amokrov/PycharmProjects/default/my_openvino_notebooks/notebooks/freevc/wavlm/modules.py:502: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert src_len, bsz == value.shape[:2]\n",
      "/mnt/c/Users/amokrov/PycharmProjects/default/my_openvino_notebooks/notebooks/freevc/wavlm/WavLM.py:372: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  feature = res[\"features\"] if ret_conv else res[\"x\"]\n",
      "/mnt/c/Users/amokrov/PycharmProjects/default/my_openvino_notebooks/notebooks/freevc/wavlm/WavLM.py:373: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if ret_layer_results:\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR = Path(\"output\")\n",
    "BASE_MODEL_NAME = \"cmodel\"\n",
    "\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "onnx_path = Path(OUTPUT_DIR / (BASE_MODEL_NAME + \"_fp32\")).with_suffix(\".onnx\")\n",
    "\n",
    "\n",
    "length = 32000\n",
    "input_shape = (1, length)\n",
    "\n",
    "input_names=['input']\n",
    "output_names = ['output']\n",
    "dummy_input = torch.randn(1, length)\n",
    "dynamic_axes= {\n",
    "    'input':{ 1: 'length'},\n",
    "    'output': {1: 'out_length'}\n",
    "}\n",
    "\n",
    "torch.onnx.export(cmodel, dummy_input, onnx_path, input_names=input_names, output_names=output_names, dynamic_axes=dynamic_axes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T00:50:16.122409Z",
     "end_time": "2023-05-02T00:50:40.452512Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "ir_cmodel = mo.convert_model(onnx_path, compress_to_fp16=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T00:51:21.032219Z",
     "end_time": "2023-05-02T00:52:04.700241Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 215, 1024)\n"
     ]
    }
   ],
   "source": [
    "from openvino.runtime import Core\n",
    "\n",
    "core = Core()\n",
    "compiled_cmodel = core.compile_model(ir_cmodel, 'CPU')\n",
    "c = compiled_cmodel(wav_src)[0]\n",
    "print(c.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T00:59:52.126160Z",
     "end_time": "2023-05-02T00:59:56.395113Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Convert SpeakerEncoder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "OpConversionFailure",
     "evalue": "Check 'unconverted_ops_types.size() == 0' failed at src/frontends/pytorch/src/frontend.cpp:72:\nFrontEnd API failed with OpConversionFailure: :\nModel wasn't fully converted. Unconverted operation types:\naten::frobenius_norm\naten::lstm\nprim::ListConstruct\n\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOpConversionFailure\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m ir_smodel \u001B[38;5;241m=\u001B[39m \u001B[43mmo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43msmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_shape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m160\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m40\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcompress_to_fp16\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/openvino/tools/mo/convert.py:351\u001B[0m, in \u001B[0;36mconvert_model\u001B[0;34m(input_model, help, framework, input, output, input_shape, batch, mean_values, scale_values, scale, reverse_input_channels, source_layout, target_layout, layout, compress_to_fp16, extensions, transform, transformations_config, silent, log_level, version, progress, stream_output, example_input, onnx_opset_version, input_model_is_text, input_checkpoint, input_meta_graph, saved_model_dir, saved_model_tags, tensorflow_custom_operations_config_update, tensorflow_object_detection_api_pipeline_config, tensorboard_logdir, tensorflow_custom_layer_libraries, input_symbol, nd_prefix_name, pretrained_model_name, save_params_from_nd, legacy_mxnet_model, enable_ssd_gluoncv, input_proto, caffe_parser_path, k, disable_omitting_optional, enable_flattening_nested_params, counts, remove_output_softmax, remove_memory, **args)\u001B[0m\n\u001B[1;32m    349\u001B[0m params\u001B[38;5;241m.\u001B[39mupdate(args)\n\u001B[1;32m    350\u001B[0m cli_parser \u001B[38;5;241m=\u001B[39m get_all_cli_parser()\n\u001B[0;32m--> 351\u001B[0m ov_model, _ \u001B[38;5;241m=\u001B[39m \u001B[43m_convert\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcli_parser\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframework\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    352\u001B[0m restore_logger_state(logger_state)\n\u001B[1;32m    353\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ov_model\n",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/openvino/tools/mo/convert_impl.py:984\u001B[0m, in \u001B[0;36m_convert\u001B[0;34m(cli_parser, framework, args, python_api_used)\u001B[0m\n\u001B[1;32m    982\u001B[0m send_conversion_result(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfail\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    983\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m python_api_used:\n\u001B[0;32m--> 984\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    985\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    986\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, argv\n",
      "\u001B[0;31mOpConversionFailure\u001B[0m: Check 'unconverted_ops_types.size() == 0' failed at src/frontends/pytorch/src/frontend.cpp:72:\nFrontEnd API failed with OpConversionFailure: :\nModel wasn't fully converted. Unconverted operation types:\naten::frobenius_norm\naten::lstm\nprim::ListConstruct\n\n"
     ]
    }
   ],
   "source": [
    "ir_smodel = mo.convert_model(smodel, input_shape=[1, 160, 40], compress_to_fp16=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Convert SynthesizerTrn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amokrov/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/torch/jit/_trace.py:1001: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Tensor-likes are not close!\n",
      "\n",
      "Mismatched elements: 320 / 320 (100.0%)\n",
      "Greatest absolute difference: 0.18093429505825043 at index (0, 0, 97) (up to 1e-05 allowed)\n",
      "Greatest relative difference: 422.0432504646249 at index (0, 0, 275) (up to 1e-05 allowed)\n",
      "  _check_trace(\n"
     ]
    },
    {
     "ename": "OpConversionFailure",
     "evalue": "Check 'unconverted_ops_types.size() == 0' failed at src/frontends/pytorch/src/frontend.cpp:72:\nFrontEnd API failed with OpConversionFailure: :\nModel wasn't fully converted. Unconverted operation types:\naten::flip\naten::randn_like\nprim::Constant\n\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOpConversionFailure\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 8\u001B[0m\n\u001B[1;32m      4\u001B[0m core \u001B[38;5;241m=\u001B[39m Core()\n\u001B[1;32m      7\u001B[0m net_g\u001B[38;5;241m.\u001B[39mforward \u001B[38;5;241m=\u001B[39m net_g\u001B[38;5;241m.\u001B[39minfer\n\u001B[0;32m----> 8\u001B[0m ir_model \u001B[38;5;241m=\u001B[39m \u001B[43mmo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnet_g\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_shape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1024\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m256\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcompress_to_fp16\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m compiled_model \u001B[38;5;241m=\u001B[39m core\u001B[38;5;241m.\u001B[39mcompile_model(ir_model, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCPU\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/openvino/tools/mo/convert.py:351\u001B[0m, in \u001B[0;36mconvert_model\u001B[0;34m(input_model, help, framework, input, output, input_shape, batch, mean_values, scale_values, scale, reverse_input_channels, source_layout, target_layout, layout, compress_to_fp16, extensions, transform, transformations_config, silent, log_level, version, progress, stream_output, example_input, onnx_opset_version, input_model_is_text, input_checkpoint, input_meta_graph, saved_model_dir, saved_model_tags, tensorflow_custom_operations_config_update, tensorflow_object_detection_api_pipeline_config, tensorboard_logdir, tensorflow_custom_layer_libraries, input_symbol, nd_prefix_name, pretrained_model_name, save_params_from_nd, legacy_mxnet_model, enable_ssd_gluoncv, input_proto, caffe_parser_path, k, disable_omitting_optional, enable_flattening_nested_params, counts, remove_output_softmax, remove_memory, **args)\u001B[0m\n\u001B[1;32m    349\u001B[0m params\u001B[38;5;241m.\u001B[39mupdate(args)\n\u001B[1;32m    350\u001B[0m cli_parser \u001B[38;5;241m=\u001B[39m get_all_cli_parser()\n\u001B[0;32m--> 351\u001B[0m ov_model, _ \u001B[38;5;241m=\u001B[39m \u001B[43m_convert\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcli_parser\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframework\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    352\u001B[0m restore_logger_state(logger_state)\n\u001B[1;32m    353\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ov_model\n",
      "File \u001B[0;32m~/.virtualenvs/my_openvino_notebooks/lib/python3.8/site-packages/openvino/tools/mo/convert_impl.py:984\u001B[0m, in \u001B[0;36m_convert\u001B[0;34m(cli_parser, framework, args, python_api_used)\u001B[0m\n\u001B[1;32m    982\u001B[0m send_conversion_result(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfail\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    983\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m python_api_used:\n\u001B[0;32m--> 984\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    985\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    986\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, argv\n",
      "\u001B[0;31mOpConversionFailure\u001B[0m: Check 'unconverted_ops_types.size() == 0' failed at src/frontends/pytorch/src/frontend.cpp:72:\nFrontEnd API failed with OpConversionFailure: :\nModel wasn't fully converted. Unconverted operation types:\naten::flip\naten::randn_like\nprim::Constant\n\n"
     ]
    }
   ],
   "source": [
    "from openvino.tools import mo\n",
    "from openvino.runtime import Core, serialize\n",
    "\n",
    "core = Core()\n",
    "\n",
    "\n",
    "net_g.forward = net_g.infer\n",
    "ir_model = mo.convert_model(net_g, input_shape=[[1, 1024, -1], [1, 256]], compress_to_fp16=True)\n",
    "compiled_model = core.compile_model(ir_model, 'CPU')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for line in tqdm(zip(titles, srcs, tgts)):\n",
    "        title, src, tgt = line\n",
    "        # tgt\n",
    "        wav_tgt, _ = librosa.load(tgt, sr=hps.data.sampling_rate)\n",
    "        wav_tgt, _ = librosa.effects.trim(wav_tgt, top_db=20)\n",
    "\n",
    "        g_tgt = smodel.embed_utterance(wav_tgt)\n",
    "        g_tgt = torch.from_numpy(g_tgt).unsqueeze(0)\n",
    "\n",
    "        # src\n",
    "        wav_src, _ = librosa.load(src, sr=hps.data.sampling_rate)\n",
    "        wav_src = torch.from_numpy(wav_src).unsqueeze(0)\n",
    "        c = utils.get_content(cmodel, wav_src)\n",
    "\n",
    "        output_layer = compiled_model.output(0)\n",
    "        audio = compiled_model((c, g_tgt))[output_layer]\n",
    "\n",
    "        timestamp = time.strftime(\"%m-%d_%H-%M\", time.localtime())\n",
    "        write(os.path.join('outputs/freevc', \"{}.wav\".format(timestamp + \"_\" + title)), hps.data.sampling_rate,\n",
    "              audio)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
